import streamlit as st
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pickle
import os

# Sayfa ayarlarÄ±
st.set_page_config(
    page_title="TÃ¼rkÃ§e SaÄŸlÄ±k AsistanÄ±",
    page_icon="ğŸ¥",
    layout="wide"
)

# BaÅŸlÄ±k
st.title("ğŸ¥ TÃ¼rkÃ§e SaÄŸlÄ±k Bilgi AsistanÄ±")
st.markdown("**43,000+ tÄ±bbi makaleden bilgi Ã§eken RAG tabanlÄ± chatbot**")
st.markdown("---")

# Session state
if 'messages' not in st.session_state:
    st.session_state.messages = []

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    api_key = os.environ.get("GEMINI_API_KEY", "")
    
    if not api_key:
        api_key = st.text_input("Gemini API Key", type="password")
        if not api_key:
            st.warning("âš ï¸ LÃ¼tfen API Key giriniz.")
    
    if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
        st.session_state.messages = []
        st.rerun()

# API key kontrol
if not api_key:
    st.info("ğŸ‘ˆ LÃ¼tfen soldaki menÃ¼den API Key giriniz.")
    st.stop()

# Model ve verileri yÃ¼kle
@st.cache_resource
def load_data():
    # Embedding model
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # Basit veri yÃ¼kleme (FAISS yerine)
    try:
        with open('medical_chunks.pkl', 'rb') as f:
            data = pickle.load(f)
        chunks = data['chunks']
        embeddings = data['embeddings']
        titles = data['titles']
    except:
        # Fallback: basit Ã¶rnek veri
        chunks = ["BaÅŸ aÄŸrÄ±sÄ± stres ve yorgunluktan kaynaklanabilir.", 
                 "Migren genellikle zonklayÄ±cÄ± baÅŸ aÄŸrÄ±sÄ± ÅŸeklinde gÃ¶rÃ¼lÃ¼r."]
        embeddings = model.encode(chunks)
        titles = ["BaÅŸ AÄŸrÄ±sÄ±", "Migren"]
    
    return model, chunks, embeddings, titles

try:
    with st.spinner("ğŸ”„ Sistem yÃ¼kleniyor..."):
        model, chunks, embeddings, titles = load_data()
        genai.configure(api_key=api_key)
        gemini_model = genai.GenerativeModel('gemini-2.5-flash')
    st.success("âœ… Sistem hazÄ±r! Soru sorabilirsiniz.")
except Exception as e:
    st.error(f"âŒ YÃ¼kleme hatasÄ±: {e}")
    st.stop()

# Basit RAG fonksiyonu
def simple_rag(question, top_k=3):
    # Soruyu encode et
    question_embedding = model.encode([question])
    
    # Cosine similarity ile benzerlik bul
    similarities = cosine_similarity(question_embedding, embeddings)[0]
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    
    # Context oluÅŸtur
    context = ""
    for idx in top_indices:
        context += f"{titles[idx]}: {chunks[idx]}\n\n"
    
    # Prompt
    prompt = f"""Sen TÃ¼rkÃ§e konuÅŸan, samimi bir saÄŸlÄ±k asistanÄ±sÄ±n.

BÄ°LGÄ°LER:
{context}

SORU: {question}

KURALLAR:
- KÄ±sa, Ã¶zlÃ¼ cevap ver (2-3 cÃ¼mle)
- Samimi ve yardÄ±msever ol
- Kaynak yoksa "Bu konuda yeterli bilgim yok" de

CEVAP:"""
    
    # Gemini'den cevap al
    try:
        response = gemini_model.generate_content(prompt)
        return response.text, [titles[i] for i in top_indices]
    except Exception as e:
        return f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {e}", []

# Chat arayÃ¼zÃ¼
st.markdown("### ğŸ’¬ Sohbet")

# MesajlarÄ± gÃ¶ster
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message:
            with st.expander("ğŸ“š Kaynaklar"):
                for source in message["sources"]:
                    st.markdown(f"- {source}")

# Yeni mesaj
if prompt := st.chat_input("SaÄŸlÄ±k hakkÄ±nda soru sorun..."):
    # KullanÄ±cÄ± mesajÄ±
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Bot cevabÄ±
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            answer, sources = simple_rag(prompt)
            st.markdown(answer)
            
            if sources:
                with st.expander("ğŸ“š Kaynaklar"):
                    for source in sources:
                        st.markdown(f"- {source}")
            
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer,
                "sources": sources
            })

# Ã–rnek sorular
if len(st.session_state.messages) == 0:
    st.markdown("### ğŸ’¡ Ã–rnek Sorular:")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ©º BaÅŸ aÄŸrÄ±sÄ± neden olur?"):
            st.rerun()
    with col2:
        if st.button("ğŸ’Š Migren belirtileri neler?"):
            st.rerun()
