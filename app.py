import streamlit as st
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pickle
import os

# Sayfa ayarlarÄ±
st.set_page_config(
    page_title="TÃ¼rkÃ§e SaÄŸlÄ±k AsistanÄ±",
    page_icon="ğŸ¥",
    layout="centered"
)

# CSS - Chat gÃ¶rÃ¼nÃ¼mÃ¼
st.markdown("""
<style>
    .user-msg {
        background-color: #e3f2fd;
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
    .bot-msg {
        background-color: #f5f5f5;
        padding: 10px;
        border-radius: 10px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

# BaÅŸlÄ±k
st.title("ğŸ¥ TÃ¼rkÃ§e SaÄŸlÄ±k AsistanÄ±")
st.caption("43,000+ tÄ±bbi makaleden bilgi Ã§eken AI chatbot")

# Session state
if 'messages' not in st.session_state:
    st.session_state.messages = []

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    
    # API Key
    api_key = os.environ.get("GEMINI_API_KEY", "")
    
    if api_key:
        st.success("âœ… API Key aktif")
    else:
        api_key = st.text_input("Gemini API Key", type="password")
        if not api_key:
            st.warning("âš ï¸ API Key gerekli")
    
    st.divider()
    
    # Bilgi
    with st.expander("ğŸ“Š Proje DetaylarÄ±"):
        st.markdown("""
        - **Dataset:** 42,804 makale
        - **Chunk:** 244,150 parÃ§a
        - **Model:** Gemini 2.5 Flash
        - **Vector DB:** FAISS
        """)
    
    # Temizle
    if st.button("ğŸ—‘ï¸ Sohbeti Temizle", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# API kontrolÃ¼
if not api_key:
    st.info("ğŸ‘ˆ LÃ¼tfen API Key giriniz")
    st.stop()

# Modelleri yÃ¼kle
@st.cache_resource
def load_models():
    embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    with open('faiss_index.pkl', 'rb') as f:
        data = pickle.load(f)
    
    return embedding_model, data['index'], data['chunks'], data['metadatas']

try:
    with st.spinner("ğŸ”„ Sistem baÅŸlatÄ±lÄ±yor..."):
        embedding_model, index, chunks, metadatas = load_models()
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
    
except Exception as e:
    st.error(f"âŒ Hata: {e}")
    st.stop()

# RAG fonksiyonu - CHATBOT TARZI
def get_response(question):
    # Embedding
    q_emb = embedding_model.encode([question])[0]
    q_emb = np.array([q_emb]).astype('float32')
    
    # FAISS arama
    distances, indices = index.search(q_emb, 5)
    
    # Context
    context_parts = []
    sources = []
    
    for idx in indices[0]:
        context_parts.append(chunks[idx][:500])
        sources.append(metadatas[idx]['title'])
    
    context = "\n\n".join(context_parts)
    
    # CHATBOT PROMPT
    # CHATBOT PROMPT
    prompt = f"""Sen uzman bir tÄ±p doktorusun. AÅŸaÄŸÄ±daki bilgileri AKILLICA kullan:

KAYNAK BÄ°LGÄ°LER:
{context}

KULLANICI SORUSU: {question}

**AKILLI KAYNAK KULLANIMI:**
- Kaynaklar GERÃ‡EKTEN ilgiliyse onlara dayan
- Kaynaklar ilgisizse KENDÄ° TIBBÄ° BÄ°LGÄ°NÄ° kullan
- Asla "kaynaklarda bilgi yok" deme
- Her zaman yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸ

**KURALLAR:**
1. Ã–nce empati kur ("GeÃ§miÅŸ olsun")
2. OlasÄ± nedenleri sÄ±rala
3. Tedavi yÃ¶ntemlerini aÃ§Ä±kla
4. Ne zaman doktora gitmeli belirt
5. Pratik Ã¶neriler ver

DETAYLI CEVAP:"""
    # Gemini cevap
    response = model.generate_content(prompt)
    
    return response.text, list(set(sources))[:3]

# Chat arayÃ¼zÃ¼
st.markdown("### ğŸ’¬ Sohbet")

# GeÃ§miÅŸ mesajlar
for msg in st.session_state.messages:
    if msg["role"] == "user":
        with st.chat_message("user"):
            st.markdown(msg["content"])
    else:
        with st.chat_message("assistant"):
            st.markdown(msg["content"])
            if "sources" in msg:
                with st.expander("ğŸ“š Kaynaklar"):
                    for i, src in enumerate(msg["sources"], 1):
                        st.caption(f"{i}. {src}")

# Yeni mesaj
if prompt := st.chat_input("SaÄŸlÄ±k hakkÄ±nda soru sorun..."):
    # KullanÄ±cÄ± mesajÄ±
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Bot cevabÄ±
    with st.chat_message("assistant"):
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            try:
                answer, sources = get_response(prompt)
                st.markdown(answer)
                
                with st.expander("ğŸ“š Kaynaklar"):
                    for i, src in enumerate(sources, 1):
                        st.caption(f"{i}. {src}")
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer,
                    "sources": sources
                })
                
            except Exception as e:
                st.error(f"âŒ Hata: {e}")

# Ä°lk aÃ§Ä±lÄ±ÅŸta Ã¶rnekler
if len(st.session_state.messages) == 0:
    st.divider()
    st.markdown("**ğŸ’¡ Ã–rnek Sorular:**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.button("ğŸ©º Diyabet nedir?", use_container_width=True)
    with col2:
        st.button("ğŸ’Š Migren nasÄ±l geÃ§er?", use_container_width=True)
    with col3:
        st.button("ğŸ¤° Hamilelik testleri", use_container_width=True)