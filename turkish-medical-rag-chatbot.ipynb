{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ğŸ¥ TÃ¼rkÃ§e SaÄŸlÄ±k Bilgi AsistanÄ± - RAG Chatbot\n\n## ğŸ“Š Proje HakkÄ±nda\nBu projede, **43,000 TÃ¼rkÃ§e tÄ±bbi makale** kullanarak bir **RAG (Retrieval Augmented Generation)** tabanlÄ± chatbot geliÅŸtireceÄŸiz.\n\n**Dataset:** alibayram/turkish-medical-articles (doktorsitesi.com)\n\n**Teknolojiler:**\n- ğŸ¤– **LLM:** Google Gemini API\n- ğŸ” **Embedding:** Sentence Transformers\n- ğŸ“¦ **Vector Database:** FAISS\n- ğŸ”— **Framework:** LangChain\n\n**Proje AkÄ±ÅŸÄ±:**\n1. Dataset yÃ¼kleme ve keÅŸif\n2. Veri temizleme\n3. Text chunking (metinleri parÃ§alara bÃ¶l)\n4. Embedding ve vector store oluÅŸturma\n5. RAG pipeline kurulumu\n6. Test ve demo","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# KÃ¼tÃ¼phane Kurulumu\n# Bu cell'i Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra \"Restart kernel\" yapman gerekebilir\n\n!pip install -q datasets huggingface_hub\n!pip install -q langchain langchain-community langchain-google-genai\n!pip install -q sentence-transformers\n!pip install -q faiss-cpu\n!pip install -q google-generativeai\n!pip install -q chromadb\n\nprint(\"âœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:50:19.424592Z","iopub.execute_input":"2025-10-20T14:50:19.425293Z","iopub.status.idle":"2025-10-20T14:50:43.716928Z","shell.execute_reply.started":"2025-10-20T14:50:19.425267Z","shell.execute_reply":"2025-10-20T14:50:43.715969Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.38.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\ngoogle-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\ngoogle-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.8.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\nlangchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\ngoogle-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\ndataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mâœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## ğŸ“‚ AdÄ±m 1: Dataset YÃ¼kleme\n\nHugging Face'ten **turkish-medical-articles** dataset'ini yÃ¼klÃ¼yoruz.\nBu dataset 43,000 TÃ¼rkÃ§e tÄ±bbi makale iÃ§eriyor.","metadata":{}},{"cell_type":"code","source":"# Hugging Face'e giriÅŸ yap (Kaggle Secrets ile)\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# Secret'tan token al\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n\n# GiriÅŸ yap\nlogin(token=HF_TOKEN)\n\nprint(\"âœ… Hugging Face'e giriÅŸ yapÄ±ldÄ±!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:50:43.718811Z","iopub.execute_input":"2025-10-20T14:50:43.719134Z","iopub.status.idle":"2025-10-20T14:50:43.863122Z","shell.execute_reply.started":"2025-10-20T14:50:43.719111Z","shell.execute_reply":"2025-10-20T14:50:43.862392Z"}},"outputs":[{"name":"stdout","text":"âœ… Hugging Face'e giriÅŸ yapÄ±ldÄ±!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Dataset'i Hugging Face'ten yÃ¼kle\nfrom datasets import load_dataset\nimport pandas as pd\n\nprint(\"ğŸ“¥ Dataset yÃ¼kleniyor...\")\n\n# Dataset'i yÃ¼kle (TIMEOUT ARTIRILMIÅ)\nimport datasets\ndatasets.config.HF_DATASETS_OFFLINE = False\n\n# Timeout'u artÄ±r\nfrom huggingface_hub import hf_api\nhf_api.HfApi().timeout = 60  # 60 saniye\n\ndataset = load_dataset(\"umutertugrul/turkish-medical-articles\", download_mode=\"force_redownload\")\n\n# Train split'ini al\ndf = pd.DataFrame(dataset['train'])\n\nprint(f\"âœ… Dataset yÃ¼klendi!\")\nprint(f\"ğŸ“Š Toplam makale sayÄ±sÄ±: {len(df)}\")\nprint(f\"ğŸ“‹ SÃ¼tunlar: {df.columns.tolist()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:50:43.863991Z","iopub.execute_input":"2025-10-20T14:50:43.864280Z","iopub.status.idle":"2025-10-20T14:50:49.268355Z","shell.execute_reply.started":"2025-10-20T14:50:43.864257Z","shell.execute_reply":"2025-10-20T14:50:49.267677Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Dataset yÃ¼kleniyor...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"doktorsitesi_articles.parquet:   0%|          | 0.00/107M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d2f3a22f0046c3bbc875b059c5e095"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sample.parquet:   0%|          | 0.00/2.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"477c663a150d411cac41d6fbb75acbcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/42804 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3e4b210d12247c0af81ac56754f7b95"}},"metadata":{}},{"name":"stdout","text":"âœ… Dataset yÃ¼klendi!\nğŸ“Š Toplam makale sayÄ±sÄ±: 42804\nğŸ“‹ SÃ¼tunlar: ['url', 'title', 'text', 'name', 'branch', 'publish_date', 'scrape_date']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## ğŸ” AdÄ±m 2: Veriyi Ä°nceleyelim\n\nDataset'in yapÄ±sÄ±nÄ± ve iÃ§eriÄŸini anlayalÄ±m.","metadata":{}},{"cell_type":"code","source":"# Veri keÅŸfi (Exploratory Data Analysis)\n\n# Ä°lk 5 satÄ±ra bakalÄ±m\nprint(\"ğŸ“„ Ä°lk 5 makale:\")\nprint(df.head())\nprint(\"\\n\" + \"=\"*80 + \"\\n\")\n\n# SÃ¼tun bilgileri\nprint(\"ğŸ“Š SÃ¼tun bilgileri:\")\nprint(df.info())\nprint(\"\\n\" + \"=\"*80 + \"\\n\")\n\n# Null (boÅŸ) deÄŸerleri kontrol et\nprint(\"â“ Eksik deÄŸerler:\")\nprint(df.isnull().sum())\nprint(\"\\n\" + \"=\"*80 + \"\\n\")\n\n# Ã–rnek bir makaleyi tamamen gÃ¶relim\nprint(\"ğŸ“° Ã–rnek Makale:\")\nprint(f\"BaÅŸlÄ±k: {df.iloc[0]['title']}\")\nprint(f\"Yazar: {df.iloc[0]['name']}\")\nprint(f\"Dal: {df.iloc[0]['branch']}\")\nprint(f\"Tarih: {df.iloc[0]['publish_date']}\")\nprint(f\"URL: {df.iloc[0]['url']}\")\nprint(f\"\\nÄ°Ã§erik (ilk 500 karakter):\\n{df.iloc[0]['text'][:500]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:50:49.269360Z","iopub.execute_input":"2025-10-20T14:50:49.269651Z","iopub.status.idle":"2025-10-20T14:50:49.365326Z","shell.execute_reply.started":"2025-10-20T14:50:49.269620Z","shell.execute_reply":"2025-10-20T14:50:49.364672Z"}},"outputs":[{"name":"stdout","text":"ğŸ“„ Ä°lk 5 makale:\n                                                 url  \\\n0  https://www.doktorsitesi.com/blog/makale/miyom...   \n1  https://www.doktorsitesi.com/blog/makale/parma...   \n2  https://www.doktorsitesi.com/blog/makale/katar...   \n3  https://www.doktorsitesi.com/blog/makale/amalg...   \n4  https://www.doktorsitesi.com/blog/makale/urtik...   \n\n                                      title  \\\n0             Miyom Belirtileri ve Tedavisi   \n1  Parmaklarla konuÅŸmak :online psikoterapi   \n2                      Katarakt ne demektir   \n3                  Amalgam Dolgu ZararlÄ± mÄ±   \n4                     Ãœrtiker ve anjiyoÃ¶dem   \n\n                                                text                     name  \\\n0  â¡ï¸Miyomlar rahim kasÄ± kaynaklÄ± iyi huylu tÃ¼mÃ¶r...  Op. Dr. Ãœlker Heydarova   \n1  Online PsikoterapiBu yÃ¼zyÄ±lÄ±n baÅŸÄ±ndayken raha...   Dr. Psk. Murat SarÄ±soy   \n2  Katarakt, gÃ¶z iÃ§indeki lensin saydamlÄ±ÄŸÄ±nÄ± kay...   Prof. Dr. ÅengÃ¼l Ã–zdek   \n3  Ã–zellikle son zamanlarda daha sÄ±k tartÄ±ÅŸÄ±lan b...   Dt. Tuba Uluneke Uygun   \n4  Deride deÄŸiÅŸik bÃ¼yÃ¼klÃ¼klerde olabilen, hafifÃ§e...    Prof. Dr. Osman Åener   \n\n                        branch    publish_date scrape_date  \n0  KadÄ±n HastalÄ±klarÄ± ve DoÄŸum    8 EylÃ¼l 2021  2025-07-09  \n1                    Psikoloji   15 EylÃ¼l 2009  2025-07-09  \n2             GÃ¶z HastalÄ±klarÄ±  19 AralÄ±k 2017  2025-07-09  \n3                   DiÅŸ Hekimi    3 Nisan 2013  2025-07-09  \n4   Dahiliye - Ä°Ã§ HastalÄ±klarÄ±    7 Åubat 2016  2025-07-09  \n\n================================================================================\n\nğŸ“Š SÃ¼tun bilgileri:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42804 entries, 0 to 42803\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   url           42804 non-null  object\n 1   title         42804 non-null  object\n 2   text          41865 non-null  object\n 3   name          42793 non-null  object\n 4   branch        42775 non-null  object\n 5   publish_date  42803 non-null  object\n 6   scrape_date   42804 non-null  object\ndtypes: object(7)\nmemory usage: 2.3+ MB\nNone\n\n================================================================================\n\nâ“ Eksik deÄŸerler:\nurl               0\ntitle             0\ntext            939\nname             11\nbranch           29\npublish_date      1\nscrape_date       0\ndtype: int64\n\n================================================================================\n\nğŸ“° Ã–rnek Makale:\nBaÅŸlÄ±k: Miyom Belirtileri ve Tedavisi\nYazar: Op. Dr. Ãœlker Heydarova\nDal: KadÄ±n HastalÄ±klarÄ± ve DoÄŸum\nTarih: 8 EylÃ¼l 2021\nURL: https://www.doktorsitesi.com/blog/makale/miyom-belirtileri-ve-tedavisi\n\nÄ°Ã§erik (ilk 500 karakter):\nâ¡ï¸Miyomlar rahim kasÄ± kaynaklÄ± iyi huylu tÃ¼mÃ¶rlerdirâ¡ï¸Miyomlar sÄ±klÄ±kla bulgu vermezler, rutin jÃ¼nekolojik mÃ¼ayenede veya baÅŸka bir nedenle yapÄ±lan radyolojik incelemelerde ortaya Ã§Ä±karâ¡ï¸En sÄ±k gÃ¶rÃ¼len bulgular dÃ¼zensiz ve yoÄŸun adet kanamalarÄ±dÄ±râ¡ï¸BÃ¼yÃ¼k boyutlara ulaÅŸmÄ±ÅŸ myomlar idrar kesesine ve baÄŸÄ±rsaklara basÄ± yaparak sÄ±k idrara Ã§Ä±kma, aÄŸrÄ±lÄ± dÄ±ÅŸkÄ±lama ve aÄŸrÄ±lÄ± iliÅŸki gibi sorunlara neden olabilmektedirâ¡ï¸MiyomlarÄ±n tedavisi ilaÃ§ ve cerrahi yÃ¶ntemlerle yapÄ±lmaktadÄ±r. Tedavi seÃ§iminde hastan...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## ğŸ§¹ AdÄ±m 3: Veri Temizleme\n\nBoÅŸ (null) text deÄŸerlerini Ã§Ä±karalÄ±m ve sadece gerekli sÃ¼tunlarÄ± tutalÄ±m.\nRAG iÃ§in sadece **title** ve **text** sÃ¼tunlarÄ±na ihtiyacÄ±mÄ±z var.","metadata":{}},{"cell_type":"code","source":"# Veri temizleme\n\n# 1. Text'i boÅŸ olan satÄ±rlarÄ± Ã§Ä±kar\ndf_clean = df[df['text'].notna()].copy()\n\nprint(f\"âœ… Temizleme Ã¶ncesi: {len(df)} makale\")\nprint(f\"âœ… Temizleme sonrasÄ±: {len(df_clean)} makale\")\nprint(f\"ğŸ—‘ï¸ Silinen: {len(df) - len(df_clean)} makale\")\n\n# 2. Sadece gerekli sÃ¼tunlarÄ± tut (title ve text)\ndf_clean = df_clean[['title', 'text']].copy()\n\n# 3. Text uzunluklarÄ±na bakalÄ±m\ndf_clean['text_length'] = df_clean['text'].str.len()\n\nprint(\"\\nğŸ“ Metin uzunluk istatistikleri:\")\nprint(df_clean['text_length'].describe())\n\n# 4. Ã‡ok kÄ±sa metinleri filtrele (100 karakterden kÄ±sa olanlar muhtemelen hatalÄ±)\ndf_clean = df_clean[df_clean['text_length'] > 100].copy()\n\nprint(f\"\\nâœ… Ã‡ok kÄ±sa metinler temizlendi\")\nprint(f\"ğŸ“Š Final veri sayÄ±sÄ±: {len(df_clean)} makale\")\n\n# text_length sÃ¼tununu sil (artÄ±k gerek yok)\ndf_clean = df_clean[['title', 'text']].copy()\n\nprint(\"\\nâœ… Veri temizleme tamamlandÄ±!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:50:49.367221Z","iopub.execute_input":"2025-10-20T14:50:49.367832Z","iopub.status.idle":"2025-10-20T14:50:49.663304Z","shell.execute_reply.started":"2025-10-20T14:50:49.367812Z","shell.execute_reply":"2025-10-20T14:50:49.662654Z"}},"outputs":[{"name":"stdout","text":"âœ… Temizleme Ã¶ncesi: 42804 makale\nâœ… Temizleme sonrasÄ±: 41865 makale\nğŸ—‘ï¸ Silinen: 939 makale\n\nğŸ“ Metin uzunluk istatistikleri:\ncount     41865.000000\nmean       4120.693849\nstd        5461.719662\nmin           2.000000\n25%        1826.000000\n50%        3002.000000\n75%        4827.000000\nmax      336572.000000\nName: text_length, dtype: float64\n\nâœ… Ã‡ok kÄ±sa metinler temizlendi\nğŸ“Š Final veri sayÄ±sÄ±: 41788 makale\n\nâœ… Veri temizleme tamamlandÄ±!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## âœ‚ï¸ AdÄ±m 4: Text Chunking (Metin BÃ¶lme)\n\nRAG sisteminde uzun metinleri kÃ¼Ã§Ã¼k parÃ§alara (chunks) bÃ¶leriz.\nBu sayede:\n- ğŸ¯ Daha hassas arama yapÄ±lÄ±r\n- ğŸ’¾ Embedding modeli daha iyi Ã§alÄ±ÅŸÄ±r\n- ğŸ” Ä°lgili bilgi daha kolay bulunur\n\n**Parametreler:**\n- **Chunk size:** 1000 karakter (her parÃ§a max 1000 karakter)\n- **Overlap:** 200 karakter (parÃ§alar arasÄ±nda 200 karakter Ã¶rtÃ¼ÅŸme)","metadata":{}},{"cell_type":"code","source":"# Text Chunking - Metinleri parÃ§alara bÃ¶l\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nprint(\"âœ‚ï¸ Metinler parÃ§alara bÃ¶lÃ¼nÃ¼yor...\")\n\n# Text splitter oluÅŸtur\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,        # Her parÃ§a max 1000 karakter\n    chunk_overlap=200,      # ParÃ§alar arasÄ± 200 karakter Ã¶rtÃ¼ÅŸme\n    length_function=len,\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Ã–nce paragraflardan bÃ¶l, sonra cÃ¼mlelerden\n)\n\n# TÃ¼m metinleri birleÅŸtir ve metadata'ya title ekle\nchunks = []\nmetadatas = []\n\nfor idx, row in df_clean.iterrows():\n    # Her makaleyi parÃ§ala\n    text_chunks = text_splitter.split_text(row['text'])\n    \n    # Her parÃ§a iÃ§in metadata ekle\n    for chunk in text_chunks:\n        chunks.append(chunk)\n        metadatas.append({\n            'title': row['title'],\n            'chunk_id': len(chunks) - 1\n        })\n\nprint(f\"âœ… Chunking tamamlandÄ±!\")\nprint(f\"ğŸ“„ Toplam makale: {len(df_clean)}\")\nprint(f\"âœ‚ï¸ Toplam chunk: {len(chunks)}\")\nprint(f\"ğŸ“Š Makale baÅŸÄ±na ortalama chunk: {len(chunks) / len(df_clean):.1f}\")\n\n# Ã–rnek bir chunk gÃ¶ster\nprint(f\"\\nğŸ“ Ã–rnek Chunk:\")\nprint(f\"BaÅŸlÄ±k: {metadatas[0]['title']}\")\nprint(f\"Ä°Ã§erik (ilk 300 karakter):\\n{chunks[0][:300]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:50:49.664009Z","iopub.execute_input":"2025-10-20T14:50:49.664201Z","iopub.status.idle":"2025-10-20T14:51:00.886192Z","shell.execute_reply.started":"2025-10-20T14:50:49.664181Z","shell.execute_reply":"2025-10-20T14:51:00.885460Z"}},"outputs":[{"name":"stdout","text":"âœ‚ï¸ Metinler parÃ§alara bÃ¶lÃ¼nÃ¼yor...\nâœ… Chunking tamamlandÄ±!\nğŸ“„ Toplam makale: 41788\nâœ‚ï¸ Toplam chunk: 244150\nğŸ“Š Makale baÅŸÄ±na ortalama chunk: 5.8\n\nğŸ“ Ã–rnek Chunk:\nBaÅŸlÄ±k: Miyom Belirtileri ve Tedavisi\nÄ°Ã§erik (ilk 300 karakter):\nâ¡ï¸Miyomlar rahim kasÄ± kaynaklÄ± iyi huylu tÃ¼mÃ¶rlerdirâ¡ï¸Miyomlar sÄ±klÄ±kla bulgu vermezler, rutin jÃ¼nekolojik mÃ¼ayenede veya baÅŸka bir nedenle yapÄ±lan radyolojik incelemelerde ortaya Ã§Ä±karâ¡ï¸En sÄ±k gÃ¶rÃ¼len bulgular dÃ¼zensiz ve yoÄŸun adet kanamalarÄ±dÄ±râ¡ï¸BÃ¼yÃ¼k boyutlara ulaÅŸmÄ±ÅŸ myomlar idrar kesesine ve b...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## ğŸ§  AdÄ±m 5: Embedding Model\n\nMetinleri **vektÃ¶rlere** (sayÄ±sal dizilere) Ã§evireceÄŸiz.\nBu sayede benzerlik aramasÄ± yapabileceÄŸiz.\n\n**Model:** `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`\n- âœ… TÃ¼rkÃ§e destekler\n- âœ… KÃ¼Ã§Ã¼k ve hÄ±zlÄ±\n- âœ… Ãœcretsiz","metadata":{}},{"cell_type":"code","source":"# Embedding model yÃ¼kle\n\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\n\nprint(\"ğŸ§  Embedding model yÃ¼kleniyor...\")\n\n# TÃ¼rkÃ§e destekleyen multilingual model\nembedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n\nprint(\"âœ… Model yÃ¼klendi!\")\n\n# Test edelim - Ã¶rnek bir cÃ¼mleyi embedding'e Ã§evir\ntest_text = \"Diyabet nedir?\"\ntest_embedding = embedding_model.encode(test_text)\n\nprint(f\"\\nğŸ§ª Test:\")\nprint(f\"Metin: '{test_text}'\")\nprint(f\"Embedding boyutu: {len(test_embedding)}\")\nprint(f\"Embedding Ã¶rneÄŸi (ilk 10 deÄŸer): {test_embedding[:10]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:51:00.886953Z","iopub.execute_input":"2025-10-20T14:51:00.887180Z","iopub.status.idle":"2025-10-20T14:51:35.372368Z","shell.execute_reply.started":"2025-10-20T14:51:00.887164Z","shell.execute_reply":"2025-10-20T14:51:35.371741Z"}},"outputs":[{"name":"stderr","text":"2025-10-20 14:51:13.208017: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760971873.419185      75 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760971873.484365      75 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"ğŸ§  Embedding model yÃ¼kleniyor...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9936149af32c4dde9968863fbd8c54aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0b891bd50e4d82b24831cc3c24905d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3e20aa7f064be38f2a78c3e5e05f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8842b27e2f3d4f48affe5f2ad7be21a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b5dd1ed148463e874bd74b84aa4816"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a51d73a2a440e88750b3b69899d604"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b8e6fa2b9a450ea496158903cb4410"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1112e10c0f24f5cbe450adae576c448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b815d135c6b54dcfbbef580460e688e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93f030eca17545938386d72db3c128da"}},"metadata":{}},{"name":"stdout","text":"âœ… Model yÃ¼klendi!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a032ca78354df18f1cbad0340574ee"}},"metadata":{}},{"name":"stdout","text":"\nğŸ§ª Test:\nMetin: 'Diyabet nedir?'\nEmbedding boyutu: 384\nEmbedding Ã¶rneÄŸi (ilk 10 deÄŸer): [ 0.13761216  0.01697462 -0.08340565 -0.00484816 -0.01542479 -0.22697556\n  0.43093085 -0.07262544  0.03188347  0.08843873]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## ğŸ“¦ AdÄ±m 6: Vector Database (FAISS)\n\nTÃ¼m chunk'larÄ± embedding'e Ã§evirip **FAISS** veritabanÄ±na kaydediyoruz.\nFAISS sayesinde milyonlarca vektÃ¶r arasÄ±nda **hÄ±zlÄ± arama** yapabiliriz.\n\nâš ï¸ **Not:** 244,150 chunk iÃ§in embedding oluÅŸturma ~10-15 dakika sÃ¼rebilir.","metadata":{}},{"cell_type":"code","source":"# FAISS Vector Database OluÅŸtur\n\nimport faiss\nfrom tqdm import tqdm\n\nprint(\"ğŸ“¦ TÃ¼m chunk'lar embedding'e Ã§evriliyor...\")\nprint(\"â³ Bu iÅŸlem 10-15 dakika sÃ¼rebilir, lÃ¼tfen bekleyin...\\n\")\n\n# TÃ¼m chunk'larÄ± embedding'e Ã§evir (batch processing iÃ§in)\nbatch_size = 100  # AynÄ± anda 100 chunk iÅŸle\nall_embeddings = []\n\nfor i in tqdm(range(0, len(chunks), batch_size)):\n    batch = chunks[i:i+batch_size]\n    batch_embeddings = embedding_model.encode(batch, show_progress_bar=False)\n    all_embeddings.extend(batch_embeddings)\n\n# Numpy array'e Ã§evir\nembeddings_array = np.array(all_embeddings).astype('float32')\n\nprint(f\"\\nâœ… Embedding'ler oluÅŸturuldu!\")\nprint(f\"ğŸ“Š Shape: {embeddings_array.shape}\")\n\n# FAISS index oluÅŸtur\nprint(\"\\nğŸ“¦ FAISS index oluÅŸturuluyor...\")\ndimension = embeddings_array.shape[1]  # 384\nindex = faiss.IndexFlatL2(dimension)  # L2 (Euclidean) mesafe\nindex.add(embeddings_array)\n\nprint(f\"âœ… FAISS index oluÅŸturuldu!\")\nprint(f\"ğŸ“Š Toplam vektÃ¶r sayÄ±sÄ±: {index.ntotal}\")\n\nprint(\"\\nğŸ‰ Vector Database hazÄ±r!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T14:51:35.373231Z","iopub.execute_input":"2025-10-20T14:51:35.373562Z","iopub.status.idle":"2025-10-20T15:00:56.762379Z","shell.execute_reply.started":"2025-10-20T14:51:35.373537Z","shell.execute_reply":"2025-10-20T15:00:56.761670Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ TÃ¼m chunk'lar embedding'e Ã§evriliyor...\nâ³ Bu iÅŸlem 10-15 dakika sÃ¼rebilir, lÃ¼tfen bekleyin...\n\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2442/2442 [09:20<00:00,  4.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nâœ… Embedding'ler oluÅŸturuldu!\nğŸ“Š Shape: (244150, 384)\n\nğŸ“¦ FAISS index oluÅŸturuluyor...\nâœ… FAISS index oluÅŸturuldu!\nğŸ“Š Toplam vektÃ¶r sayÄ±sÄ±: 244150\n\nğŸ‰ Vector Database hazÄ±r!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## ğŸ¤– AdÄ±m 7: RAG Pipeline - Gemini API Entegrasyonu\n\nÅimdi tÃ¼m parÃ§alarÄ± birleÅŸtiriyoruz:\n1. ğŸ” KullanÄ±cÄ± soru sorar\n2. ğŸ§  Soruyu embedding'e Ã§eviririz\n3. ğŸ“¦ FAISS'te en benzer chunk'larÄ± buluruz\n4. ğŸ¤– Gemini'ye chunk'larÄ± + soruyu gÃ¶nderip cevap alÄ±rÄ±z","metadata":{}},{"cell_type":"code","source":"# Gemini API Kurulumu (Kaggle Secrets ile)\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n# Secret'tan API key al\nuser_secrets = UserSecretsClient()\nGEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n\ngenai.configure(api_key=GEMINI_API_KEY)\n\n# Gemini model oluÅŸtur\nmodel = genai.GenerativeModel('gemini-2.5-flash')\n\nprint(\"âœ… Gemini API hazÄ±r!\")\n\n# Test edelim\ntest_response = model.generate_content(\"Merhaba, nasÄ±lsÄ±n?\")\nprint(f\"\\nğŸ§ª Test:\")\nprint(f\"Cevap: {test_response.text}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:00:56.763211Z","iopub.execute_input":"2025-10-20T15:00:56.763479Z","iopub.status.idle":"2025-10-20T15:00:58.217467Z","shell.execute_reply.started":"2025-10-20T15:00:56.763459Z","shell.execute_reply":"2025-10-20T15:00:58.216581Z"}},"outputs":[{"name":"stdout","text":"âœ… Gemini API hazÄ±r!\n\nğŸ§ª Test:\nCevap: Merhaba! Ben iyiyim, teÅŸekkÃ¼r ederim. Sen nasÄ±lsÄ±n?\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## ğŸ”— AdÄ±m 8: RAG Fonksiyonu - Soru Cevaplama\n\nÅimdi tÃ¼m parÃ§alarÄ± birleÅŸtirip soru-cevap fonksiyonunu oluÅŸturuyoruz!","metadata":{}},{"cell_type":"code","source":"# RAG Soru-Cevap Fonksiyonu\n\ndef rag_query(question, top_k=5):\n    \"\"\"\n    RAG sistemi ile soru cevaplama\n    \n    Args:\n        question: KullanÄ±cÄ±nÄ±n sorusu\n        top_k: KaÃ§ chunk getirileceÄŸi (varsayÄ±lan 5)\n    \n    Returns:\n        answer: Gemini'nin cevabÄ±\n        sources: KullanÄ±lan kaynaklar\n    \"\"\"\n    \n    # 1. Soruyu embedding'e Ã§evir\n    question_embedding = embedding_model.encode([question])[0]\n    question_embedding = np.array([question_embedding]).astype('float32')\n    \n    # 2. FAISS'te en benzer chunk'larÄ± bul\n    distances, indices = index.search(question_embedding, top_k)\n    \n    # 3. Ä°lgili chunk'larÄ± ve baÅŸlÄ±klarÄ±nÄ± al\n    retrieved_chunks = []\n    retrieved_titles = []\n    \n    for idx in indices[0]:\n        retrieved_chunks.append(chunks[idx])\n        retrieved_titles.append(metadatas[idx]['title'])\n    \n    # 4. Context oluÅŸtur (chunk'larÄ± birleÅŸtir)\n    context = \"\\n\\n---\\n\\n\".join([\n        f\"Kaynak: {title}\\n{chunk}\" \n        for title, chunk in zip(retrieved_titles, retrieved_chunks)\n    ])\n    \n    # 5. Gemini'ye prompt gÃ¶nder\n    prompt = f\"\"\"Sen TÃ¼rkÃ§e tÄ±bbi bir asistansÄ±n. AÅŸaÄŸÄ±daki tÄ±bbi makalelerden yararlanarak soruyu cevapla.\n\nKAYNAKLARDAN ALINAN BÄ°LGÄ°LER:\n{context}\n\nSORU: {question}\n\nCEVAP: YukarÄ±daki kaynaklara dayanarak, soruyu aÃ§Ä±k ve anlaÅŸÄ±lÄ±r bir ÅŸekilde TÃ¼rkÃ§e olarak cevaplayÄ±n. EÄŸer kaynaklarda bilgi yoksa, \"Bu konuda kaynaklarda yeterli bilgi bulunamadÄ±\" deyin.\"\"\"\n\n    # 6. Gemini'den cevap al\n    response = model.generate_content(prompt)\n    answer = response.text\n    \n    # 7. Benzersiz baÅŸlÄ±klarÄ± bul (kaynak olarak gÃ¶stermek iÃ§in)\n    unique_sources = list(set(retrieved_titles))\n    \n    return answer, unique_sources\n\nprint(\"âœ… RAG fonksiyonu hazÄ±r!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:00:58.218303Z","iopub.execute_input":"2025-10-20T15:00:58.218580Z","iopub.status.idle":"2025-10-20T15:00:58.225169Z","shell.execute_reply.started":"2025-10-20T15:00:58.218561Z","shell.execute_reply":"2025-10-20T15:00:58.224371Z"}},"outputs":[{"name":"stdout","text":"âœ… RAG fonksiyonu hazÄ±r!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## ğŸ§ª AdÄ±m 9: RAG Sistemini Test Edelim!\n\nSisteme Ã¶rnek sorular soralÄ±m ve cevaplarÄ± gÃ¶relim.","metadata":{}},{"cell_type":"code","source":"# RAG Sistemini Test Et\n\nprint(\"ğŸ§ª RAG Sistemi Test Ediliyor...\\n\")\nprint(\"=\"*80)\n\n# Test Sorusu 1\nquestion1 = \"Diyabet nedir ve belirtileri nelerdir?\"\nprint(f\"\\nâ“ SORU 1: {question1}\\n\")\n\nanswer1, sources1 = rag_query(question1, top_k=3)\nprint(f\"ğŸ¤– CEVAP:\\n{answer1}\\n\")\nprint(f\"ğŸ“š KAYNAKLAR: {', '.join(sources1[:3])}\")\n\nprint(\"\\n\" + \"=\"*80)\n\n# Test Sorusu 2\nquestion2 = \"Migren aÄŸrÄ±sÄ± nasÄ±l geÃ§er?\"\nprint(f\"\\nâ“ SORU 2: {question2}\\n\")\n\nanswer2, sources2 = rag_query(question2, top_k=3)\nprint(f\"ğŸ¤– CEVAP:\\n{answer2}\\n\")\nprint(f\"ğŸ“š KAYNAKLAR: {', '.join(sources2[:3])}\")\n\nprint(\"\\n\" + \"=\"*80)\n\n# Test Sorusu 3\nquestion3 = \"Hamilelerde yapÄ±lan testler nelerdir?\"\nprint(f\"\\nâ“ SORU 3: {question3}\\n\")\n\nanswer3, sources3 = rag_query(question3, top_k=3)\nprint(f\"ğŸ¤– CEVAP:\\n{answer3}\\n\")\nprint(f\"ğŸ“š KAYNAKLAR: {', '.join(sources3[:3])}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nâœ… Test tamamlandÄ±! RAG sistemi baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor! ğŸ‰\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:00:58.226275Z","iopub.execute_input":"2025-10-20T15:00:58.226582Z","iopub.status.idle":"2025-10-20T15:01:13.588351Z","shell.execute_reply.started":"2025-10-20T15:00:58.226559Z","shell.execute_reply":"2025-10-20T15:01:13.587441Z"}},"outputs":[{"name":"stdout","text":"ğŸ§ª RAG Sistemi Test Ediliyor...\n\n================================================================================\n\nâ“ SORU 1: Diyabet nedir ve belirtileri nelerdir?\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8823f15fe87640ccb4d2308c9b0bac31"}},"metadata":{}},{"name":"stdout","text":"ğŸ¤– CEVAP:\nBu konuda kaynaklarda yeterli bilgi bulunamadÄ±. Kaynaklar, Ã¼lseratif kolit ve Crohn hastalÄ±ÄŸÄ± hakkÄ±nda bilgi iÃ§ermektedir.\n\nğŸ“š KAYNAKLAR: Ãœlseratif  kolit  ve crohn  hastalÄ±ÄŸÄ± hakkÄ±nda, Ãœlseratif kolit hakkÄ±nda merak edilenler\n\n================================================================================\n\nâ“ SORU 2: Migren aÄŸrÄ±sÄ± nasÄ±l geÃ§er?\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be893e3b9e56421498d17af2180f71be"}},"metadata":{}},{"name":"stdout","text":"ğŸ¤– CEVAP:\nYukarÄ±daki kaynaklara gÃ¶re, migren aÄŸrÄ±sÄ±nÄ±n nasÄ±l geÃ§tiÄŸine dair doÄŸrudan ve detaylÄ± bir aÃ§Ä±klama bulunmamaktadÄ±r. Ancak bir kaynakta ÅŸu bilgi yer almaktadÄ±r:\n\n*   \"Uyuyabilirse Ã§oÄŸu hastada aÄŸrÄ± hafifler ve geÃ§er.\"\n\nBu bilgiye gÃ¶re, birÃ§ok migren hastasÄ±nda aÄŸrÄ±, uyuyabildiÄŸinde hafiflemekte ve geÃ§mektedir. Hastalar genellikle loÅŸ, sessiz bir odada istirahati tercih ederler, bu da aÄŸrÄ±nÄ±n hafiflemesine yardÄ±mcÄ± olabilecek bir durumdur.\n\nğŸ“š KAYNAKLAR: Hava deÄŸiÅŸimleri baÅŸ aÄŸrÄ±sÄ±nÄ± tetikliyor, Migren !, Migren nedir, kesin Ã§Ã¶zÃ¼mÃ¼ var mÄ±dÄ±r?\n\n================================================================================\n\nâ“ SORU 3: Hamilelerde yapÄ±lan testler nelerdir?\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"683b9946e7a64c0e8e17d3bd176e5791"}},"metadata":{}},{"name":"stdout","text":"ğŸ¤– CEVAP:\nHamilelerde yapÄ±lan testler, kaynaklarda belirtildiÄŸi Ã¼zere baÅŸlÄ±ca ÅŸu ÅŸekildedir:\n\n1.  **GebeliÄŸin Tespiti ve Normal Seyrinin Belirlenmesi:**\n    *   Adet gecikmesi durumunda idrar veya kanla yapÄ±lan tahliller yardÄ±mÄ±yla gebeliÄŸin varlÄ±ÄŸÄ± tespit edilir.\n    *   Gebelik testleri pozitifse, dÄ±ÅŸ gebelik, boÅŸ gebelik veya mol (Ã¼zÃ¼m) gebeliÄŸi gibi durumlarÄ± ekarte etmek ve gebeliÄŸin normal olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in testler yapÄ±lÄ±r.\n\n2.  **Gebelik Tarama Testleri (FetÃ¼steki Kromozomal ve Genetik HastalÄ±k Riskini DeÄŸerlendirmek Ä°Ã§in):**\n    *   **Birinci Trimester Tarama Testi:** Anneye kan testi ve fetÃ¼se ense kalÄ±nlÄ±ÄŸÄ± Ã¶lÃ§Ã¼mÃ¼ yapÄ±larak Down Sendromu ve diÄŸer kromozomal anomaliler aÃ§Ä±sÄ±ndan risk skoru oluÅŸturulur.\n    *   **Ä°kinci Trimester Tarama Testi (ÃœÃ§lÃ¼/DÃ¶rtlÃ¼ Test):** Anneye kan testi ve fetÃ¼se ense kalÄ±nlÄ±ÄŸÄ± Ã¶lÃ§Ã¼mÃ¼ yapÄ±larak Down Sendromu, AÃ§Ä±k NÃ¶ral TÃ¼p Defekti ve Trisomi 18 aÃ§Ä±sÄ±ndan risk deÄŸerlendirmesi yapÄ±lÄ±r.\n    *   **Harmonik Tarama Testi:** Anneye yapÄ±lan tek kan testi ile plasentadan salgÄ±lanan Ã¶zel proteinlerin seviyeleri Ã¶lÃ§Ã¼lerek Down Sendromu, Trisomi 18 ve Trisomi 13 aÃ§Ä±sÄ±ndan risk deÄŸerlendirmesi yapÄ±lÄ±r.\n\n3.  **Rutin Prenatal Kontroller SÄ±rasÄ±nda YapÄ±lanlar:**\n    *   Tansiyon Ã¶lÃ§Ã¼mÃ¼\n    *   Kilo takibi\n    *   Ultrasonografi\n    *   Hemoglobin analizleri\n    *   Ä°drar analizleri\n\nBu testler dÃ¼zenli prenatal kontroller esnasÄ±nda yapÄ±lÄ±r ve sonuÃ§lar Ã¶nceki bulgularla kÄ±yaslanÄ±r.\n\nğŸ“š KAYNAKLAR: Normal Gebelik Takibi!!, Gebelik Tarama Testleri, Gebelik takibi hangi sÄ±klÄ±kla olmalÄ±?\n\n================================================================================\n\nâœ… Test tamamlandÄ±! RAG sistemi baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor! ğŸ‰\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## ğŸŒ AdÄ±m 10: Streamlit Web ArayÃ¼zÃ¼\n\nÅimdi kullanÄ±cÄ±larÄ±n kolayca kullanabileceÄŸi bir web arayÃ¼zÃ¼ oluÅŸturacaÄŸÄ±z.\nBu arayÃ¼z Streamlit ile hazÄ±rlanacak ve deploy edilecek.","metadata":{}},{"cell_type":"code","source":"# Streamlit Web ArayÃ¼zÃ¼ Kodu OluÅŸtur\n\nstreamlit_code = '''\nimport streamlit as st\nimport google.generativeai as genai\nfrom sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\nimport pickle\n\n# Sayfa ayarlarÄ±\nst.set_page_config(\n    page_title=\"TÃ¼rkÃ§e SaÄŸlÄ±k AsistanÄ±\",\n    page_icon=\"ğŸ¥\",\n    layout=\"wide\"\n)\n\n# BaÅŸlÄ±k\nst.title(\"ğŸ¥ TÃ¼rkÃ§e SaÄŸlÄ±k Bilgi AsistanÄ±\")\nst.markdown(\"**43,000+ tÄ±bbi makaleden bilgi Ã§eken RAG tabanlÄ± chatbot**\")\nst.markdown(\"---\")\n\n# API Key giriÅŸi (sidebar)\nwith st.sidebar:\n    st.header(\"âš™ï¸ Ayarlar\")\n    api_key = st.text_input(\"Gemini API Key\", type=\"password\")\n    \n    st.markdown(\"---\")\n    st.markdown(\"### ğŸ“Š Proje Bilgileri\")\n    st.info(\"\"\"\n    - **Dataset:** 42,804 TÃ¼rkÃ§e tÄ±bbi makale\n    - **Chunk:** 244,150 parÃ§a\n    - **Model:** Gemini 2.5 Flash\n    - **Embedding:** Multilingual MiniLM\n    - **Vector DB:** FAISS\n    \"\"\")\n\n# Ana iÃ§erik\nif not api_key:\n    st.warning(\"âš ï¸ LÃ¼tfen soldaki menÃ¼den Gemini API Key giriniz.\")\n    st.stop()\n\n# Model ve verileri yÃ¼kle (cache ile)\n@st.cache_resource\ndef load_models_and_data():\n    # Embedding model\n    embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    \n    # FAISS index ve chunks yÃ¼kle\n    with open('faiss_index.pkl', 'rb') as f:\n        data = pickle.load(f)\n    \n    index = data['index']\n    chunks = data['chunks']\n    metadatas = data['metadatas']\n    \n    return embedding_model, index, chunks, metadatas\n\ntry:\n    embedding_model, index, chunks, metadatas = load_models_and_data()\n    \n    # Gemini yapÄ±landÄ±r\n    genai.configure(api_key=api_key)\n    model = genai.GenerativeModel('gemini-2.5-flash')\n    \n    st.success(\"âœ… Sistem hazÄ±r! Soru sorabilirsiniz.\")\n    \nexcept Exception as e:\n    st.error(f\"âŒ Model yÃ¼klenirken hata: {e}\")\n    st.stop()\n\n# Soru-cevap fonksiyonu\ndef rag_query(question, top_k=5):\n    # Soruyu embedding'e Ã§evir\n    question_embedding = embedding_model.encode([question])[0]\n    question_embedding = np.array([question_embedding]).astype('float32')\n    \n    # FAISS'te ara\n    distances, indices = index.search(question_embedding, top_k)\n    \n    # Chunk'larÄ± al\n    retrieved_chunks = []\n    retrieved_titles = []\n    \n    for idx in indices[0]:\n        retrieved_chunks.append(chunks[idx])\n        retrieved_titles.append(metadatas[idx]['title'])\n    \n    # Context oluÅŸtur\n    context = \"\\\\n\\\\n---\\\\n\\\\n\".join([\n        f\"Kaynak: {title}\\\\n{chunk}\" \n        for title, chunk in zip(retrieved_titles, retrieved_chunks)\n    ])\n    \n    # Prompt\n    prompt = f\"\"\"Sen TÃ¼rkÃ§e tÄ±bbi bir asistansÄ±n. AÅŸaÄŸÄ±daki tÄ±bbi makalelerden yararlanarak soruyu cevapla.\n\nKAYNAKLARDAN ALINAN BÄ°LGÄ°LER:\n{context}\n\nSORU: {question}\n\nCEVAP: YukarÄ±daki kaynaklara dayanarak, soruyu aÃ§Ä±k ve anlaÅŸÄ±lÄ±r bir ÅŸekilde TÃ¼rkÃ§e olarak cevaplayÄ±n.\"\"\"\n\n    # Gemini'den cevap al\n    response = model.generate_content(prompt)\n    answer = response.text\n    \n    unique_sources = list(set(retrieved_titles))\n    \n    return answer, unique_sources\n\n# Soru giriÅŸi\nst.markdown(\"### ğŸ’¬ Sorunuzu Sorun\")\n\ncol1, col2 = st.columns([4, 1])\n\nwith col1:\n    question = st.text_input(\"\", placeholder=\"Ã–rn: Diyabet nedir ve belirtileri nelerdir?\")\n\nwith col2:\n    top_k = st.selectbox(\"Kaynak sayÄ±sÄ±\", [3, 5, 7], index=1)\n\nif st.button(\"ğŸ” Sorgula\", type=\"primary\"):\n    if question:\n        with st.spinner(\"ğŸ¤” Cevap hazÄ±rlanÄ±yor...\"):\n            try:\n                answer, sources = rag_query(question, top_k=top_k)\n                \n                st.markdown(\"### ğŸ¤– Cevap\")\n                st.markdown(answer)\n                \n                st.markdown(\"---\")\n                st.markdown(\"### ğŸ“š KullanÄ±lan Kaynaklar\")\n                for i, source in enumerate(sources[:5], 1):\n                    st.markdown(f\"{i}. {source}\")\n                    \n            except Exception as e:\n                st.error(f\"âŒ Hata oluÅŸtu: {e}\")\n    else:\n        st.warning(\"âš ï¸ LÃ¼tfen bir soru girin.\")\n\n# Ã–rnek sorular\nst.markdown(\"---\")\nst.markdown(\"### ğŸ’¡ Ã–rnek Sorular\")\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    if st.button(\"Diyabet nedir?\"):\n        st.session_state.example_q = \"Diyabet nedir ve belirtileri nelerdir?\"\n\nwith col2:\n    if st.button(\"Migren nasÄ±l geÃ§er?\"):\n        st.session_state.example_q = \"Migren aÄŸrÄ±sÄ± nasÄ±l geÃ§er?\"\n\nwith col3:\n    if st.button(\"Hamilelik testleri\"):\n        st.session_state.example_q = \"Hamilelerde yapÄ±lan testler nelerdir?\"\n'''\n\n# DosyayÄ± kaydet\nwith open('app.py', 'w', encoding='utf-8') as f:\n    f.write(streamlit_code)\n\nprint(\"âœ… app.py dosyasÄ± oluÅŸturuldu!\")\nprint(\"ğŸ“ Dosya yolu: app.py\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:01:13.589662Z","iopub.execute_input":"2025-10-20T15:01:13.590040Z","iopub.status.idle":"2025-10-20T15:01:13.598957Z","shell.execute_reply.started":"2025-10-20T15:01:13.590019Z","shell.execute_reply":"2025-10-20T15:01:13.598098Z"}},"outputs":[{"name":"stdout","text":"âœ… app.py dosyasÄ± oluÅŸturuldu!\nğŸ“ Dosya yolu: app.py\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## ğŸ’¾ AdÄ±m 11: FAISS Index ve Verileri Kaydet\n\nStreamlit uygulamasÄ±nÄ±n kullanabilmesi iÃ§in FAISS index, chunks ve metadatalarÄ± kaydediyoruz.","metadata":{}},{"cell_type":"code","source":"# FAISS Index ve verileri kaydet\n\nimport pickle\nimport os\n\nprint(\"ğŸ’¾ FAISS index ve veriler kaydediliyor...\")\n\n# TÃ¼m verileri bir dictionary'e koy\ndata_to_save = {\n    'index': index,\n    'chunks': chunks,\n    'metadatas': metadatas\n}\n\n# Pickle ile kaydet\nwith open('faiss_index.pkl', 'wb') as f:\n    pickle.dump(data_to_save, f)\n\nprint(\"âœ… FAISS index kaydedildi!\")\nprint(\"ğŸ“ Dosya: faiss_index.pkl\")\nprint(f\"ğŸ“Š Dosya boyutu: {round(os.path.getsize('faiss_index.pkl') / (1024*1024), 2)} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:01:13.599842Z","iopub.execute_input":"2025-10-20T15:01:13.600144Z","iopub.status.idle":"2025-10-20T15:01:15.726629Z","shell.execute_reply.started":"2025-10-20T15:01:13.600114Z","shell.execute_reply":"2025-10-20T15:01:15.725941Z"}},"outputs":[{"name":"stdout","text":"ğŸ’¾ FAISS index ve veriler kaydediliyor...\nâœ… FAISS index kaydedildi!\nğŸ“ Dosya: faiss_index.pkl\nğŸ“Š Dosya boyutu: 561.0 MB\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## ğŸ“¦ AdÄ±m 12: requirements.txt OluÅŸtur\n\nDeploy iÃ§in gerekli kÃ¼tÃ¼phaneleri listeleyen dosyayÄ± oluÅŸturuyoruz.","metadata":{}},{"cell_type":"code","source":"# requirements.txt oluÅŸtur\n\nrequirements = \"\"\"streamlit==1.31.0\ngoogle-generativeai==0.3.2\nsentence-transformers==2.3.1\nfaiss-cpu==1.7.4\nnumpy==1.24.3\npandas==2.0.3\ndatasets==2.16.1\nhuggingface-hub==0.20.3\n\"\"\"\n\nwith open('requirements.txt', 'w') as f:\n    f.write(requirements)\n\nprint(\"âœ… requirements.txt oluÅŸturuldu!\")\nprint(\"\\nğŸ“‹ Ä°Ã§erik:\")\nprint(requirements)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:01:15.728480Z","iopub.execute_input":"2025-10-20T15:01:15.728756Z","iopub.status.idle":"2025-10-20T15:01:15.733612Z","shell.execute_reply.started":"2025-10-20T15:01:15.728737Z","shell.execute_reply":"2025-10-20T15:01:15.732841Z"}},"outputs":[{"name":"stdout","text":"âœ… requirements.txt oluÅŸturuldu!\n\nğŸ“‹ Ä°Ã§erik:\nstreamlit==1.31.0\ngoogle-generativeai==0.3.2\nsentence-transformers==2.3.1\nfaiss-cpu==1.7.4\nnumpy==1.24.3\npandas==2.0.3\ndatasets==2.16.1\nhuggingface-hub==0.20.3\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## ğŸ‰ Proje TamamlandÄ±!\n\n### âœ… YapÄ±lanlar:\n1. âœ… **Dataset yÃ¼klendi:** 42,804 TÃ¼rkÃ§e tÄ±bbi makale\n2. âœ… **Veri temizlendi:** 41,788 temiz makale\n3. âœ… **Chunking yapÄ±ldÄ±:** 244,150 parÃ§a oluÅŸturuldu\n4. âœ… **Embedding model:** Multilingual MiniLM yÃ¼klendi\n5. âœ… **FAISS index:** Vector database oluÅŸturuldu\n6. âœ… **RAG pipeline:** Soru-cevap sistemi Ã§alÄ±ÅŸÄ±yor\n7. âœ… **Streamlit app:** Web arayÃ¼zÃ¼ hazÄ±r\n8. âœ… **Dosyalar:** app.py, faiss_index.pkl, requirements.txt\n\n### ğŸ“ OluÅŸturulan Dosyalar:\n- `app.py` - Streamlit web uygulamasÄ±\n- `faiss_index.pkl` - FAISS vector database (561 MB)\n- `requirements.txt` - Gerekli kÃ¼tÃ¼phaneler\n\n### ğŸš€ Sonraki AdÄ±mlar:\n1. **GitHub'a yÃ¼kle:** Notebook + dosyalar\n2. **Deploy et:** Hugging Face Spaces veya Streamlit Cloud\n3. **README.md yaz:** Proje dokÃ¼mantasyonu","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}